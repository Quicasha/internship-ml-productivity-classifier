# Occupancy Prediction from Environmental Sensor Data

> End-to-end machine learning project for room occupancy detection using environmental sensor data.

---

## ğŸ“Œ Project Overview

This project focuses on predicting **room occupancy** based on environmental sensor measurements.
The objective is to evaluate how well different machine learning models can infer **human presence**
from physical signals such as temperature, humidity, light intensity, COâ‚‚ concentration, and derived features.

The project is implemented as a **complete machine learning pipeline**, covering:

- data loading and preprocessing,
- baseline modeling,
- supervised model training,
- robust evaluation and comparison,
- and analysis of model behavior.

A strong emphasis is placed on **proper evaluation practices** to avoid misleading results caused by
data leakage or overly optimistic train/test splits.

---

## ğŸ¯ Problem Definition

Given **time-ordered sensor measurements**, the task is to classify whether a room is:

- **occupied (1)**  
- **not occupied (0)**  

at a given time step.

This is a **binary classification problem with temporal structure**, meaning that
model evaluation must respect the **chronological order of the data**.

---

## ğŸ§  Why This Problem Matters

Accurate occupancy detection has practical, real-world applications such as:

- ğŸ¢ smart building automation,
- âš¡ energy efficiency optimization,
- â„ï¸ HVAC system control,
- ğŸ”’ privacy-preserving presence detection (no cameras involved).

The dataset used in this project is **widely referenced in academic literature**,
making it suitable both for learning purposes and realistic experimentation.

---

## ğŸ“ Project Structure

```text
internship-ml-productivity-classifier/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ occupancy.csv
â”‚       # Original time-ordered environmental sensor dataset
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ load_data.py
â”‚   â”‚   # Dataset loading utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   # Feature selection and dataset preparation logic
â”‚   â”‚
â”‚   â”œâ”€â”€ clean_data.py
â”‚   â”‚   # Data cleaning and optional time-based feature engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   # Centralized metric computation and formatted evaluation output
â”‚   â”‚
â”‚   â”œâ”€â”€ train_dummy.py
â”‚   â”‚   # Baseline model (DummyClassifier â€“ most frequent class)
â”‚   â”‚
â”‚   â”œâ”€â”€ train_logistic.py
â”‚   â”‚   # Logistic Regression model with feature scaling
â”‚   â”‚
â”‚   â”œâ”€â”€ train_random_forest.py
â”‚   â”‚   # Random Forest classifier
â”‚   â”‚
â”‚   â”œâ”€â”€ cross_validation.py
â”‚   â”‚   # Cross-validation logic for robust model evaluation
â”‚   â”‚
â”‚   â”œâ”€â”€ compare_models.py
â”‚   â”‚   # Unified model comparison and result aggregation
â”‚   â”‚
â”‚   â”œâ”€â”€ ablation_plot.py
â”‚   â”‚   # Feature ablation analysis and visualization
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_importance.py
â”‚   â”‚   # Random Forest feature importance analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ realtime_simulation.py
â”‚   â”‚   # Sliding-window simulation to mimic online prediction behavior
â”‚   â”‚
â”‚   â””â”€â”€ run.py
â”‚       # Main entry point (CLI) for training, evaluation, and comparison
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ model_comparison.csv
â”‚   â”‚   # Side-by-side performance comparison of all models
â”‚   â”‚
â”‚   â”œâ”€â”€ metrics_cv.csv
â”‚   â”‚   # Cross-validation summary statistics
â”‚   â”‚
â”‚   â”œâ”€â”€ metrics_cv_folds.csv
â”‚   â”‚   # Per-fold cross-validation metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”‚   # Feature importance visualization
â”‚   â”‚
â”‚   â””â”€â”€ ablation_test.png
â”‚       # Feature ablation accuracy comparison
â”‚
â”œâ”€â”€ notebooks/
â”‚   # Optional exploratory notebooks
â”‚
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .gitignore
â”‚
â””â”€â”€ README.md
```
---

## ğŸš€ How to Run
This project is designed to be executed via a single CLI entry point (run.py).
No notebooks are required to reproduce results.

### 1. Environment setup

```text
Python 3.10+
```

Create virtual environment (recommended)
```bash
python -m venv .venv
```

Activate it:
- Windows
```bash
.venv/Scripts/activate
```

- Linux/macOS
```bash
source .venv/bin/activate
```

Install dependencies
```bash
pip install -r requirements.txt
```

### 2. Dataset

The dataset is expected at:
```bash
data/occupancy.csv
```

It is a time-ordered environmental sensor dataset with the following columns:
- Temperature
- Humidity
- Light
- CO2
- HumidityRatio
- Occupancy (target label: 0 or 1)
No manual preprocessing is required before running the pipeline.


### 3. Train individual models

All training scripts can be executed directly, but the recommended way is via ```run.py```.

Random Forest
```bash
python src/run.py train --model rf
```

Logistic Regression (with feature scaling)
```bash
python src/run.py train --model logreg
```

Baseline (DummyClassifier â€“ most frequent class)
```bash
python src/run.py train --model dummy
```

Each command prints:
- confusion matrix,
- precision / recall / F1,
- overall accuracy.

